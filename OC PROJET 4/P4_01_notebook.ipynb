{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Predire si un client rembourse un crédit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\" alt=\"logo\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette analyse on se limite aux fichiers **\"application_train.csv\"** et **\"application_test.csv\"** (et \"HomeCredit_columns_description.csv\" pour les informations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "# data display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "\n",
    "# models\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, fbeta_score, make_scorer\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# feature engineering\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# model explanation\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data,columns=[],seuil_Sup=None,seuil_Inf=None):\n",
    "    '''\n",
    "    seuils inferieur et superieur sont > <\n",
    "    '''\n",
    "    res = data.copy()\n",
    "    if len(columns) == 0: columns = data.columns\n",
    "        \n",
    "    # if threshold sup undefined\n",
    "    if seuil_Sup == None:\n",
    "        seuil_Sup = []\n",
    "        print(\"default threshold: Q3 + (1.5*IQR) \")\n",
    "        for col in columns:\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            # IQR is interquartile range\n",
    "            IQR = Q3 - Q1\n",
    "            limite = Q3 + (1.5*IQR)\n",
    "            seuil_Sup.append(limite)\n",
    "            print(\"for \"+col+\", threshold sup is: \"+str(limite))\n",
    "            \n",
    "    # if threshold inf undefined\n",
    "    if seuil_Inf == None:\n",
    "        seuil_Inf = []\n",
    "        print()\n",
    "        print(\"default threshold: Q3 - (1.5*IQR) \")\n",
    "        for col in columns:\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            # IQR is interquartile range\n",
    "            IQR = Q3 - Q1\n",
    "            limite = Q1 - (1.5*IQR)\n",
    "            seuil_Inf.append(limite)\n",
    "            print(\"for \"+col+\", threshold inf is: \"+str(limite))\n",
    "    k = 0\n",
    "    print()\n",
    "    for col in columns:\n",
    "        #res.loc[res[col] >= seuil[k], col] = None\n",
    "        res = res.drop(res[res[col] > seuil_Sup[k]].index)\n",
    "        res = res.drop(res[res[col] < seuil_Inf[k]].index)\n",
    "        print(\"ROWS after cleaning \"+col+\" : \"+ str(len(res)))\n",
    "        k += 1\n",
    "        \n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_conf(test_Y, prediction_report):\n",
    "    report = classification_report(test_Y, prediction_report,output_dict=True)\n",
    "    recall0 = round(report[\"0\"][\"recall\"]*100,2)\n",
    "    recall1 = round(report[\"1\"][\"recall\"]*100,2)\n",
    "    fbeta = fbeta_score(test_Y, prediction_report, average='micro', beta=0.5)\n",
    "    #print(classification_report(test_Y, prediction_report))\n",
    "    conf_matrix = confusion_matrix(test_Y, prediction_report, labels=[1, 0])\n",
    "    cmtx = pd.DataFrame(\n",
    "        conf_matrix, \n",
    "        index=['real:1', 'real:0'], \n",
    "        columns=['pred:1', 'pred:0']\n",
    "    )\n",
    "    total_pred = len(test_Y)\n",
    "\n",
    "    print(\"1 = non rembourse\")\n",
    "    print()\n",
    "    print(cmtx)\n",
    "    print()\n",
    "    print(\"recall 0: \"+ str(report[\"0\"][\"recall\"]))\n",
    "    print(\"recall 1: \"+ str(report[\"1\"][\"recall\"]))\n",
    "    print(\"f beta score: \"+str(fbeta))\n",
    "    print()\n",
    "    print(\"Nos criteres:\")\n",
    "    print(\"I) on detecte \"+str(recall1)+\" % de classe 1\")\n",
    "    print(\"II) on detecte \"+str(recall0)+\" % de classe 0\")\n",
    "    \n",
    "    return [recall1,recall0,fbeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "data_train = pd.read_csv('data/application_train.csv')\n",
    "\n",
    "# Testing data features\n",
    "data_test = pd.read_csv('data/application_test.csv')\n",
    "\n",
    "# Testing data features\n",
    "data_info = pd.read_csv('data/HomeCredit_columns_description.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Présentation générale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe à predire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape: ', data_train.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_dif = [x for x in data_train.columns if x not in data_test.columns]\n",
    "print(\"What we want to predict: \"+str(col_dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=data_train, x=\"TARGET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes 0 et 1 à prédire sont **disproportionnées**.\\\n",
    "Il faudra agir en consequence plus tard (voir partie \"Modeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de ce fichier sera utile pour comprendre le dataset et determiner de nouvelles variables plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = data_info[data_info[\"Table\"] == \"application_{train|test}.csv\"]\n",
    "data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_NaN(data, limite = 0):\n",
    "    nb_nan = data.isna().sum()\n",
    "    # pour voir que les colonnes avec NaN > limite\n",
    "    nb_nan = nb_nan[nb_nan.values >= limite]\n",
    "\n",
    "    d = {'Variables': nb_nan.index, 'Number of NaN': nb_nan.values}\n",
    "    nb_nan_df = pd.DataFrame(data=d)\n",
    "    plt.figure(figsize=(18, 8))\n",
    "\n",
    "    nb_nan_df1 = nb_nan_df\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    ax = sns.barplot(x=\"Variables\", y=\"Number of NaN\", data=nb_nan_df1)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    ax.set_title('Nombre de \\\"NaN\\\" par variable', fontdict= { 'fontsize': 24, 'fontweight':'bold'})\n",
    "    \n",
    "plot_NaN(data_train, limite = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données num (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_numerical = data_train.select_dtypes(include=np.number)\n",
    "data_numerical.drop(['SK_ID_CURR'], axis=1, inplace=False).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données cat (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_categorical = data_train.select_dtypes(exclude=np.number)\n",
    "data_categorical.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données normalisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des données normalisées pour verifer leurs distribution.\\\n",
    "Ici, on voit que les distributions ne comporte pas d'extreme.\\\n",
    "**Pas besoin de les re-nettoyer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_normalized = data_info[data_info[\"Special\"] == \"normalized\"][\"Row\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_normalized:\n",
    "    if col in data_numerical.columns:\n",
    "        ax = sns.violinplot(x=data_train[col])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection des individus (empreins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On verifie qu'aucun ID apparait à la fois dans le dataset train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = data_train.loc[data_train.SK_ID_CURR.isin(data_test.SK_ID_CURR)]\n",
    "print(\"Same id in train/test:\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On verifie qu'aucun ID apparait plusieurs fois dans le dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre d'individus original: \"+ str(data_train.shape[0]))\n",
    "data_train.drop_duplicates(subset=['SK_ID_CURR'], keep = 'first', inplace=True)\n",
    "print(\"Nombre d'individus en verifiant les doublons dans \\'code\\': \"+ str(data_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "data_train = pd.get_dummies(data_train, drop_first=True)\n",
    "data_test = pd.get_dummies(data_test, drop_first=True)\n",
    "\n",
    "print('Training Features shape: ', data_train.shape)\n",
    "print('Testing Features shape: ', data_test.shape)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garder les mêmes colones pour les 2 dataset (OHE peut créer differentes colonnes si des valeurs n'apparaissent pas dans un dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = data_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "data_train, data_test = data_train.align(data_test, join = 'inner', axis = 1)\n",
    "\n",
    "print('Training Features shape: ', data_train.shape)\n",
    "print('Testing Features shape: ', data_test.shape)\n",
    "\n",
    "# Add the target back in\n",
    "data_train['TARGET'] = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs methodes de feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature1 = data_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminer variables fortement corrélées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data_feature1.drop(['TARGET'], axis=1, inplace=False)\n",
    "df = pd.DataFrame(X)\n",
    "cor_matrix = df.corr().abs()\n",
    "\n",
    "fig = plt.figure(figsize=[12,6])\n",
    "sns.heatmap(cor_matrix.loc[[\"FLOORSMAX_AVG\",\"FLOORSMAX_MEDI\",\"FLOORSMAX_MODE\"],[\"FLOORSMAX_AVG\",\"FLOORSMAX_MEDI\",\"FLOORSMAX_MODE\"]], annot=True)\n",
    "#sns.heatmap(cor_matrix.iloc[0:15,0:15], annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On élimine les variables présentant **95%** de similarité "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(cor_matrix)\n",
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n",
    "#print(upper_tri)\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "print(\"col to drop:\"); print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(to_drop, axis=1)\n",
    "print(\"From \" + str(len(data_feature1.columns)) + \" columns, to \"+ str(len(df1.columns)) + \" columns\")\n",
    "data_feature1 = df1\n",
    "data_feature1[\"TARGET\"] = data_train['TARGET']\n",
    "data_feature1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Garder les variables avec de la variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde les variables avec un minimum de variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data_train.drop(\"TARGET\",axis=1)\n",
    "#data_X.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(0.02)\n",
    "selector.fit(data_X)\n",
    "#selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature1 = data_X.iloc[:,selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature1[\"TARGET\"] = data_train[\"TARGET\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"On garde \"+ str(sum(selector.get_support())) +\" sur \"+ str(len(df1.columns)) +\" variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables conservées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On suprime les variable inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_feature1.drop(\"SK_ID_CURR\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(data_feature1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage Valeurs aberrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci dessous la description de nos variables actuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_column = [info in data_feature1.nunique()[data_feature1.nunique() > 3].index for info in data_info[\"Row\"]]\n",
    "infos = data_info[mask_column]\n",
    "\n",
    "display(infos)\n",
    "data_feature1[data_feature1.nunique()[data_feature1.nunique() > 3].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de valeur aberrante, avec la variable \"DAYS_EMPLOYED\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=data_train[\"DAYS_EMPLOYED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On élimine les valeurs aberrantes des variables non normalisées et non categorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_clean = ['AMT_REQ_CREDIT_BUREAU_YEAR', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "                'OWN_CAR_AGE', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE', 'DAYS_BIRTH',\n",
    "                'DAYS_EMPLOYED', 'AMT_CREDIT', 'HOUR_APPR_PROCESS_START', \"AMT_INCOME_TOTAL\", \"CNT_CHILDREN\",\n",
    "                \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\", \"CNT_FAM_MEMBERS\", \"HOUR_APPR_PROCESS_START\",\n",
    "                \"AMT_REQ_CREDIT_BUREAU_WEEK\", \"AMT_REQ_CREDIT_BUREAU_MON\", \"AMT_REQ_CREDIT_BUREAU_QRT\",\n",
    "                \"OBS_60_CNT_SOCIAL_CIRCLE\", \"OBS_30_CNT_SOCIAL_CIRCLE\"\n",
    "               ]\n",
    "\n",
    "limites_sup = [99, 9, 9,\n",
    "               None, 0, 0, 0, 0,\n",
    "               0, 99999999, 24, 99999999, 99, \n",
    "               None, None, 99, 24,\n",
    "              99, 99, 99,\n",
    "              99, 99]\n",
    "\n",
    "limites_inf = [0, 0, 0,\n",
    "               0, -36500, -36500, -36500, -36500,\n",
    "               -36500, 0, 0, 0, 0,\n",
    "               0, 0, 0, 0,\n",
    "              0, 0, 0,\n",
    "              0, 0]\n",
    "\n",
    "data_feature1 = cleaning(data_feature1, col_to_clean, seuil_Sup = limites_sup, seuil_Inf = limites_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage Valeurs atypiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature1.nunique()[data_feature1.nunique() > 3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in data_feature1.nunique()[data_feature1.nunique() > 3].index:\n",
    "    print(col + \" :\")\n",
    "    #ax = sns.boxplot(x=data_numerical[col])\n",
    "    #plt.show()\n",
    "    df = data_feature1[col]\n",
    "    fig = px.box(df, y=col)#, log_y=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On exclu certaines colonnes pour le nettoyage des valeurs atypiques (ces colonnes ayant des valeurs atypiques justifiées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAYS_EMPLOYED  ? FLOORSMIN_.. ?\n",
    "col_to_not_clean = [\"CNT_CHILDREN\",\"CNT_FAM_MEMBERS\", \"HOUR_APPR_PROCESS_START\",\n",
    "                    \"DEF_30_CNT_SOCIAL_CIRCLE\", \"DEF_60_CNT_SOCIAL_CIRCLE\",\"AMT_REQ_CREDIT_BUREAU_WEEK\",\n",
    "                    \"AMT_REQ_CREDIT_BUREAU_MON\",\"AMT_REQ_CREDIT_BUREAU_QRT\",\"AMT_REQ_CREDIT_BUREAU_YEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col_to_clean.remove(ele) for ele in col_to_not_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug ?\n",
    "# ce nom de colonne n'est pas reconnu si dans liste \"col_to_not_clean\"\n",
    "col_to_clean.remove(\"HOUR_APPR_PROCESS_START\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature1 = cleaning(data_feature1, col_to_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation Valeurs manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(data_feature1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On impute les variables categorielles par leurs modes, puis les varaibles numeriques par leurs moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data_feature1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nb_unique = data_feature1.nunique()\n",
    "\n",
    "col_categorical = col_nb_unique[col_nb_unique <= 3].index\n",
    "col_not_categorical = col_nb_unique[col_nb_unique > 3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[data_feature1[col].fillna(data_feature1[col].mean(), inplace=True) for col in col_not_categorical]\n",
    "[data_feature1[col].fillna(data_feature1[col].mode(), inplace=True) for col in col_categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation post-traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "profil de **classe 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_feature1[data_feature1[\"TARGET\"] == 1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "profil de **classe 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature1[data_feature1[\"TARGET\"] == 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(data_feature1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons la relation entre les variables non categoriels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataPrint = data_feature1[col_not_categorical]\n",
    "dataPrint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=data_numerical[\"EXT_SOURCE_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column_to_visualize = data_feature1.columns\n",
    "Column_to_visualize = [\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]\n",
    "\n",
    "for col in Column_to_visualize:\n",
    "    ax = sns.violinplot(x=\"TARGET\", y=col, data=data_feature1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPrint = dataPrint.iloc[:1000,:5]\n",
    "toPrint[\"TARGET\"] = data_feature1[\"TARGET\"]\n",
    "sns.pairplot(toPrint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPrint = dataPrint.iloc[:1000,5:10]\n",
    "toPrint[\"TARGET\"] = data_feature1[\"TARGET\"]\n",
    "sns.pairplot(toPrint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPrint = dataPrint.iloc[:1000,10:]\n",
    "toPrint[\"TARGET\"] = data_feature1[\"TARGET\"]\n",
    "sns.pairplot(toPrint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_feature1.drop(\"TARGET\",axis=1)\n",
    "y = data_feature1[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attendre un moment ci dessous 30min?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(\n",
    "   n_jobs = -1, \n",
    "   max_depth = 5\n",
    ")\n",
    "boruta = BorutaPy(\n",
    "   estimator = forest, \n",
    "   n_estimators = 'auto',\n",
    "   max_iter = 50 # number of trials to perform\n",
    ")### fit Boruta (it accepts np.array, not pd.DataFrame)\n",
    "boruta.fit(np.array(X), np.array(y))### print results\n",
    "green_area = X.columns[boruta.support_].to_list()\n",
    "blue_area = X.columns[boruta.support_weak_].to_list()\n",
    "print('features in the green area:', green_area)\n",
    "print('features in the blue area:', blue_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''features in the green area: ['DAYS_REGISTRATION', 'DAYS_BIRTH', 'EXT_SOURCE_3', 'EXT_SOURCE_2', 'EXT_SOURCE_1', 'DAYS_EMPLOYED', 'AMT_CREDIT']\n",
    "features in the blue area: ['FLAG_DOCUMENT_3', 'DAYS_ID_PUBLISH']\n",
    "\n",
    "features in the green area: ['AMT_CREDIT', 'AMT_ANNUITY', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "features in the blue area: ['AMT_GOODS_PRICE']\n",
    "\n",
    "features in the green area: ['AMT_CREDIT', 'AMT_ANNUITY', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "features in the blue area: ['AMT_GOODS_PRICE', 'DAYS_REGISTRATION', 'FLAG_DOCUMENT_3']\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On garde les variables utiles lors des classifications avec la methode \"boruta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_feature2 = data_feature1[green_area+blue_area]\n",
    "data_feature2[\"TARGET\"] = data_feature1[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinaison de variables avec la documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nombre de mois* pour rembourser avec le salaire en entier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature2[\"mois_remboursement\"] = data_feature1[\"AMT_CREDIT\"]/(data_feature1[\"AMT_INCOME_TOTAL\"]/12)\n",
    "data_feature2[\"mois_remboursement\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nombre de mois* pour rembourser avec le salaire diviser par le nombre d'enfant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature2[\"mois_remboursement_enfant\"] = data_feature1[\"AMT_CREDIT\"]/((data_feature1[\"AMT_INCOME_TOTAL\"]/12)*(data_feature1[\"CNT_CHILDREN\"]+1))\n",
    "data_feature2[\"mois_remboursement_enfant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "le salaire diviser par le nombre d'enfant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature2[\"salaire_enfant\"] = (data_feature1[\"AMT_INCOME_TOTAL\"]/12)/(data_feature1[\"CNT_CHILDREN\"]+1)\n",
    "data_feature2[\"salaire_enfant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features SCALE train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1, test_X1, train_Y1, test_Y1 = train_test_split(data_feature1.drop(\"TARGET\",axis=1),data_feature1[\"TARGET\"],test_size=0.3)\n",
    "train_X2, test_X2, train_Y2, test_Y2 = train_test_split(data_feature2.drop(\"TARGET\",axis=1),data_feature2[\"TARGET\"],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = train_X1.columns\n",
    "features2 = train_X2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale data train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "train_X1 = sc.fit_transform(train_X1)\n",
    "test_X1 = sc.transform (test_X1)\n",
    "\n",
    "train_X2 = sc.fit_transform(train_X2)\n",
    "test_X2 = sc.transform(test_X2)\n",
    "\n",
    "test_X1 = pd.DataFrame(test_X1, columns=features1)\n",
    "test_X2 = pd.DataFrame(test_X2, columns=features2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour contrer le **déséquilibre des classes** dans nos données, on associe des poids (une importance) plus grands à la classe sous représentée (la classe 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_1 = sum(data_feature2[\"TARGET\"])\n",
    "print(\"number of class 1: \"+ str(nbr_1)+\"/\"+str(data_feature2[\"TARGET\"].shape[0]))\n",
    "proportion1 = nbr_1/data_feature2[\"TARGET\"].shape[0]\n",
    "proportion0 = 1-proportion1\n",
    "print(\"=> \"+str(round(proportion1*100,2))+\"% of the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all results for all the choices of features\n",
    "resultats = []\n",
    "\n",
    "# all results for a choice of features\n",
    "ALL_RES = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix des features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X, test_X, train_Y, test_Y, features = train_X1, test_X1, train_Y1, test_Y1, features1\n",
    "train_X, test_X, train_Y, test_Y, features = train_X2, test_X2, train_Y2, test_Y2, features2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel sont les metriques qui nous interesse ?\n",
    "\n",
    "**1) accorder un minimum de prêt qui ne seront pas remboursés**\\\n",
    " => detecter les personne non fiables\\\n",
    " => maximiser recall de la classe 1 (non rembourseur de prêt)\n",
    "\n",
    "**2) accorder un maximum de prêt qui seront remboursés**\\\n",
    " => detecter les personne fiables\\\n",
    " => maximiser recall de la classe 0 (rembourseur de prêt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Un compromis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **F-beta score** is the weighted harmonic mean of precision and recall, reaching its optimal value at 1 and its worst value at 0.\n",
    "\n",
    "The beta parameter determines the weight of recall in the combined score. beta < 1 lends more weight to precision, while beta > 1 favors recall (beta -> 0 considers only precision, beta -> +inf only recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive model (most freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(train_X, train_Y)\n",
    "pred_dummy = dummy_clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_RES[\"most freq\"] = matrix_conf(test_Y, pred_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression gridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait varier la regularisation du modele avec un grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = smaller values specify stronger regularization.\n",
    "grid={\"C\":np.logspace(-3,3,7)}#, \"penalty\":[\"l1\",\"l2\"]}\n",
    "lr = LogisticRegression(class_weight={0:1-proportion0,1:1-proportion1})\n",
    "logreg_cv=GridSearchCV(lr,grid,cv=10, scoring=ftwo_scorer)\n",
    "\n",
    "logreg_cv.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère la prédiction de la valeur positive\n",
    "y_prob = logreg_cv.predict_proba(test_X)[:,1] \n",
    "\n",
    "# On créé un vecteur de prédiction à partir du vecteur de probabilités\n",
    "y_pred = np.where(y_prob > 0.5, 1, 0) \n",
    "\n",
    "y_prob_train = logreg_cv.predict_proba(train_X)[:,1] \n",
    "y_pred_train = np.where(y_prob_train > 0.5, 1, 0)\n",
    "\n",
    "# no need to display ROC curve (can't compare with other models)\n",
    "\n",
    "#false_positive_rate, true_positive_rate, thresholds = roc_curve(test_Y, y_prob)\n",
    "#roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement global "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables utilisées par le modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = logreg_cv.best_estimator_.coef_[0]\n",
    "\n",
    "d = {'features': features, 'score': features_importance}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "df[\"score\"] = df[\"score\"].abs()\n",
    "df = df.sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perfs_dic = {'Modeles': res.iloc[2].index, 'fbeta score': res.iloc[2].values}\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "perfs = pd.DataFrame(data=df)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"features\", y=\"score\", data=perfs)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "ax.set_title('Features usage by the model', fontdict= { 'fontsize': 24, 'fontweight':'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_conf(train_Y, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_RES[\"logistic reg\"] = matrix_conf(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement local "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple de decision (SHAP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Kernel SHAP to explain test set predictions\n",
    "k_explainer = shap.KernelExplainer(logreg_cv.best_estimator_.predict_proba, pd.DataFrame(train_X).iloc[0:100])\n",
    "\n",
    "rand = randint(0, len(test_X)-1)\n",
    "k_shap_values = k_explainer.shap_values(pd.DataFrame(test_X).iloc[rand])\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(k_explainer.expected_value[1], k_shap_values[1], pd.DataFrame(test_X).iloc[rand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tree gridSearch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un arbre de decision permet une **interpretation simple** de la prediction du classifieur\\\n",
    "+\n",
    "Decision trees frequently perform well on imbalanced data\\\n",
    "+\n",
    "efficace avec des données booléennes (ou categoriels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6]}\n",
    "tree_models = GridSearchCV(DecisionTreeClassifier(class_weight={0:1-proportion0,1:1-proportion1}), tree_para, cv=5, scoring = 'recall')\n",
    "tree_models.fit(train_X, train_Y)\n",
    "\n",
    "pred_tree_grid = tree_models.predict(test_X)\n",
    "pred_tree_grid_train = tree_models.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.best_params_\n",
    "tree_models.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement global "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables utilisées par le modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = tree_models.best_estimator_.feature_importances_\n",
    "\n",
    "d = {'features': features, 'score': features_importance}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "df[\"score\"] = df[\"score\"].abs()\n",
    "df = df.sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perfs_dic = {'Modeles': res.iloc[2].index, 'fbeta score': res.iloc[2].values}\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "perfs = pd.DataFrame(data=df)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"features\", y=\"score\", data=perfs)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "ax.set_title('Features usage by the model', fontdict= { 'fontsize': 24, 'fontweight':'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage de l'arbre de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(tree_models.best_estimator_, feature_names=features, filled=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_conf(train_Y, pred_tree_grid_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALL_RES[\"decision tree\"] = matrix_conf(test_Y, pred_tree_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement local "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple de decision (SHAP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(tree_models.best_estimator_)\n",
    "\n",
    "# Calculate Shap values\n",
    "rand = randint(0, len(test_X)-1)\n",
    "shap_values = explainer.shap_values(pd.DataFrame(test_X).iloc[rand])\n",
    "\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], pd.DataFrame(test_X).iloc[rand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(max_iter = 100, kernel = 'linear', probability = True)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "pred_SVM = clf.predict(test_X)\n",
    "pred_SVM_train = clf.predict(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement global "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables utilisées par le modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt = {\"coef\":clf.coef_[0], \"feature\":features}\n",
    "#df = pd.DataFrame(data=dt)\n",
    "#df.sort_values(by=['coef'], ascending=False)\n",
    "\n",
    "features_importance = clf.coef_[0]\n",
    "\n",
    "d = {'features': features, 'score': features_importance}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "df[\"score\"] = df[\"score\"].abs()\n",
    "df = df.sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perfs_dic = {'Modeles': res.iloc[2].index, 'fbeta score': res.iloc[2].values}\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "perfs = pd.DataFrame(data=df)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"features\", y=\"score\", data=perfs)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "ax.set_title('Features usage by the model', fontdict= { 'fontsize': 24, 'fontweight':'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_conf(train_Y, pred_SVM_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALL_RES[\"SVM\"] = matrix_conf(test_Y, pred_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement local "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple de decision (SHAP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Kernel SHAP to explain test set predictions\n",
    "k_explainer = shap.KernelExplainer(clf.predict_proba, pd.DataFrame(train_X).iloc[0:100])\n",
    "\n",
    "rand = randint(0, len(test_X)-1)\n",
    "k_shap_values = k_explainer.shap_values(pd.DataFrame(test_X).iloc[rand])\n",
    "shap.force_plot(k_explainer.expected_value[1], k_shap_values[1], pd.DataFrame(test_X).iloc[rand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest gridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_param = {'max_depth':[4,5,6], 'n_estimators':[5,8,10]}\n",
    "#rf_model = GridSearchCV(RandomForestClassifier(class_weight={0:0.1,1:1}), forest_param, cv=5, scoring = 'recall')\n",
    "rf_models = GridSearchCV(RandomForestClassifier(class_weight={0:1-proportion0,1:1-proportion1}), forest_param, cv=5, scoring = ftwo_scorer)\n",
    "\n",
    "# fit your model\n",
    "rf_models.fit(train_X, train_Y)\n",
    "\n",
    "pred_forest = rf_models.predict(test_X)\n",
    "pred_forest_train = rf_models.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_models.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement global "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables utilisées par le modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = rf_model.feature_importances_\n",
    "\n",
    "d = {'features': features, 'score': features_importance}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "df[\"score\"] = df[\"score\"].abs()\n",
    "df = df.sort_values('score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#perfs_dic = {'Modeles': res.iloc[2].index, 'fbeta score': res.iloc[2].values}\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "perfs = pd.DataFrame(data=df)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"features\", y=\"score\", data=perfs)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "ax.set_title('Features usage by the model', fontdict= { 'fontsize': 24, 'fontweight':'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Un des arbres** de decision du meilleur model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(rf_model.estimators_[0], feature_names=features, filled=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_conf(train_Y, pred_forest_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les données de **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ALL_RES[\"forest\"] = matrix_conf(test_Y, pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctionnement local "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple de decision (SHAP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "rand = randint(0, len(test_X)-1)\n",
    "shap_values = explainer.shap_values(pd.DataFrame(test_X).iloc[rand])\n",
    "\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], pd.DataFrame(test_X).iloc[rand])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation de nos modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats.append(pd.DataFrame(ALL_RES, index=['detection des non rembourseurs (recall 1)',\n",
    "                                         'detection des rembourseurs (recall 0)','compromis (fbeta score)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in resultats:\n",
    "    display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perfs_dic = {'Modeles': res.iloc[2].index, 'fbeta score': res.iloc[2].values}\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "perfs = pd.DataFrame(data=perfs_dic)\n",
    "perfs = perfs.sort_values('fbeta score',ascending=False)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Modeles\", y=\"fbeta score\", data=perfs)\n",
    "ax.set_title('fbeta scores for each model', fontdict= { 'fontsize': 24, 'fontweight':'bold'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le meilleur de nos modeles ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peux enfin entrainer le meilleur sur toutes nos données pour l'utiliser sur de nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data_feature2.drop(\"TARGET\",axis=1), data_feature2[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_models.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer le gain de nos modeles  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definir clairement les metriques à optimiser.\\\n",
    "Nottament mesurer les pertes/gains pour les differents types d'erreur afin de selectionner le modele avec le compromis le plus avantageux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliser d'autres approches de pre-traitement des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec des mesures de correlation avec la classe (teste du chi2, square, lightgbm)\\\n",
    "Avec les autres fichier à disposition (avec l'id \"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"datas.png\" alt=\"logo\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliser d'autres modeles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD classifier ? kernel approx ? optimisation des modeles avec XGboost ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_OC_project2",
   "language": "python",
   "name": "env_oc_project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
